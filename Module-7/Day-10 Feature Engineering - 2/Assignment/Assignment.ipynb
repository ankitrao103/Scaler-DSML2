{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1. Co2 Emissions\n",
    "\n",
    "The below data represents the carbon dioxide emission from vehicles in grams/per km. There are a few missing values present in the data.\n",
    "\n",
    "What will be the imputing strategy that we can use?\n",
    "\n",
    "data=[50,196,221,136,255,NaN,230,252,267,212,NaN,359,328,200,500,624,NaN,236,289,300,366]\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "data=np.array(data)\n",
    "\n",
    "imputer = SimpleImputer(strategy = “________”)\n",
    "\n",
    "data1= imputer.fit_transform(data.reshape(-1,1))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correct option: median\n",
    "\n",
    "### Explanation:\n",
    "\n",
    "![](https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/003/012/original/missing_values.PNG?1648541322)\n",
    "\n",
    "\n",
    "Since there are 3 outliers present in the data, we should use the median as an impute strategy.\n",
    "\n",
    "In the presence of outliers, or extreme values, the median is preferred over the mean.\n",
    "The reason for this is that the mean can be “dragged” up or down by extreme values, but since the median is just the middle value in a distribution, it is not influenced by the outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2. Missing_values\n",
    "\n",
    "You are cleaning up a DataFrame that has almost 5000 observations and you notice that one of the categorical columns contains 1512 missing values.\n",
    "\n",
    "What strategy should you apply to deal with these missing values?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correct option: Impute the missing values with the most_frequent value.\n",
    "\n",
    "\n",
    "### Explanation:\n",
    "\n",
    "- Since the column is categorical we can replace it with the most frequent value.\n",
    "- We cannot drop all the rows which will result in loss of information and we might lose some important data.\n",
    "- We cannot replace all the values with randomly selected values either. There is no sense of doing this.\n",
    "- We cannot drop the entire column that contains missing values as it may result in a huge loss of important data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3. Imputer Works\n",
    "\n",
    "What does the following code snippet do?\n",
    "```python\n",
    "from sklearn.impute\n",
    "import SimpleImputer\n",
    "imp_mean = SimpleImputer( strategy='mean')\n",
    "imp_mean.fit(data)\n",
    "imputed_train_df = imp_mean.transform(data)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correct option: Calculates the mean of the non-missing values in a column and then replacing the missing values within each column separately\n",
    "\n",
    "### Explanation:\n",
    "\n",
    "SimpleImputer() replace missing values using a descriptive statistic (e.g. mean, median, or most frequent) along each column or using a constant value.\n",
    "\n",
    "when strategy=’mean’ is passed inside, it calculates the mean of the non-missing values in a column and then replaces the missing values within each column separately"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q4. Car company\n",
    "\n",
    "The below data represents the Carbon Dioxide emissions from a vehicle.\n",
    "\n",
    "![](https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/003/013/original/co2_em.PNG?1648541586)\n",
    "\n",
    "\n",
    "There are 11 features and 1 target column. In the independent variables “Make” represents 42 unique car companies.\n",
    "\n",
    "Which feature engineering technique can be applied to this column?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correct option: Feature Binning\n",
    "\n",
    "### Explanation:\n",
    "\n",
    "\n",
    "If we do one hot encoding it will increase the cardinality issue and most of the data will be sparse data.\n",
    "We cannot apply feature scaling or feature engineering / transformation as it is not a numeric feature.\n",
    "We can do feature binning by dividing the 42 unique car companies into 4 categories, for example, Luxury, Sports, Premium, and General cars.\n",
    "\n",
    "Code:\n",
    "```python\n",
    "\n",
    "print('Initial column:\\n', data['Make'].unique())\n",
    "\n",
    "data['Make_Type'] = data['Make'].replace(['BUGATTI', 'PORSCHE', 'MASERATI', 'ASTON MARTIN', 'LAMBORGHINI' 'JAGUAR','SRT'], 'Sports')\n",
    "\n",
    "data['Make_Type'] = data['Make_Type'].replace(['ALFA ROMEO', 'AUDI', 'BMW', 'BUICK', 'CADILLAC', 'CHRYSLER', 'DODGE', 'GMC','INFINITI', 'JEEP', 'LAND ROVER', 'LEXUS', 'MERCEDES-BENZ','MINI', 'SMART', 'VOLVO'], 'Premium')\n",
    "\n",
    "data['Make_Type'] = data['Make_Type'].replace(['ACURA', 'BENTLEY', 'LINCOLN', 'ROLLS-ROYCE', 'GENESIS'], 'Luxury')\n",
    "\n",
    "data['Make_Type'] = data['Make_Type'].replace(['CHEVROLET', 'FIAT', 'FORD', 'KIA', 'HONDA', 'HYUNDAI', 'MAZDA', 'MITSUBISHI','NISSAN', 'RAM', 'SCION', 'SUBARU', 'TOYOTA', 'VOLKSWAGEN'], 'General')\n",
    "\n",
    "print('Final column:\\n', data['Make_Type'].unique())\n",
    "\n",
    "### Output:\n",
    "\n",
    "Initial column:\n",
    "array([‘ACURA’, ‘ALFA ROMEO’, ‘ASTON MARTIN’, ‘AUDI’, ‘BENTLEY’, ‘BMW’, ‘BUICK’, ‘CADILLAC’, ‘CHEVROLET’, ‘CHRYSLER’, ‘DODGE’, ‘FIAT’,’FORD’, ‘GMC’, ‘HONDA’, ‘HYUNDAI’, ‘INFINITI’, ‘JAGUAR’, ‘JEEP’,’KIA’, ‘LAMBORGHINI’, ‘LAND ROVER’, ‘LEXUS’, ‘LINCOLN’, ‘MASERATI’,’MAZDA’, ‘MERCEDES-BENZ’, ‘MINI’, ‘MITSUBISHI’, ‘NISSAN’,’PORSCHE’, ‘RAM’, ‘ROLLS-ROYCE’, ‘SCION’, ‘SMART’, ‘SRT’, ‘SUBARU’,’TOYOTA’, ‘VOLKSWAGEN’, ‘VOLVO’, ‘GENESIS’, ‘BUGATTI’],dtype=object) - These are 42 unique types.\n",
    "\n",
    "### Final column:\n",
    "array([‘Sports’, ‘Premium’, ‘Luxury’, ‘General’],dtype=object) - These are 4 unique types.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q5. Text messages\n",
    "\n",
    "Data on the number of text messages sent one weekend by girls and boys in school is summarized as follows:\n",
    "\n",
    "![](https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/002/865/original/text_msg.PNG?1647936406)\n",
    "\n",
    "A Statistics student checking the calculations finds that the message counts for all the students were underreported by 5.\n",
    "\n",
    "If the numbers are corrected, what are the corrected IQR and standard deviation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correct option: IQR = 76 and standard deviation = 42.4\n",
    "\n",
    "### Explanation:\n",
    "\n",
    "Adding the same constant to every value will increase the Min, Q1, Median, Q3, Max, and Mean by that constant.\n",
    "\n",
    "However, measures of variability, including the IQR and the standard deviation, will remain unchanged.\n",
    "\n",
    "If you add a constant to every value, the distance between values does not change.\n",
    "As a result, all of the measures of variability (range, interquartile range, standard deviation, and variance) remain the same.\n",
    "\n",
    "On the other hand, suppose you multiply every value by a constant. This has the effect of multiplying the range, interquartile range (IQR), and standard deviation by that constant.\n",
    "\n",
    "Thus, IQR = Q3 - Q1 = 90-14 =76\n",
    "and standard deviation = 42.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q6. Limits for outlier\n",
    "\n",
    "For a certain array [0, 1, 2, 3, 4, 5, 10], we decided to plot a boxplot as below:\n",
    "\n",
    "![](https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/026/837/original/yticks.PNG?1677576157)\n",
    "\n",
    "According to the above plot, calculate the upper limit, median, and lower limit, such that, a data point would be considered as an outlier if it is out of those limits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correct option: 9, 3, -3\n",
    "\n",
    "### Explanation:\n",
    "\n",
    "Here, we can observe from the given boxplot that : Q3 = 4.5 and Q1 = 1.5.\n",
    "Therefore, IQR = Q3 - Q1 = 3\n",
    "\n",
    "upper limit = Q3+1.5(IQR) = 4.5+1.5(3) = 9\n",
    "\n",
    "lower limit = Q1- 1.5(IQR) = 1.5 - 1.5(3) = -3\n",
    "\n",
    "Any observation greater than upper limit and anything lower than lower limit is considered to be an outlier.\n",
    "\n",
    "Median from the boxplot can easily confirmed as 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q7. Standardization vs Normalization\n",
    "\n",
    "Read below statements regarding two data transformation techniques Standardization and Normalization.\n",
    "```python\n",
    "A : Normalization forces all features to come down to same range\n",
    "\n",
    "B : Standardization computes the z-score of all values which makes the feature mean = 0 \n",
    "```\n",
    "\n",
    "Mark statements A and B as True or False."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correct Option: A : True, B : True\n",
    "\n",
    "### Explanation:\n",
    "- Statement A\n",
    "\n",
    "  True.\n",
    "  Normalization is a technique that scales the individual features to have the same range.\n",
    "  It brings the values of different features into a comparable range, often between 0 and 1.\n",
    "- Statement B:\n",
    "\n",
    "  True\n",
    "  Standardization (or z-score normalization) scales the features in such a way that they have a mean of 0 and a standard deviation of 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correct Option: Both features will have a mean of 0 and a standard deviation of 1.\n",
    "\n",
    "### Explanation:\n",
    "When you apply Standard Scaling (Standardization) using the Standard Scaler, it transforms the data in such a way that the resulting features have a mean of 0 and a standard deviation of 1.\n",
    "This is achieved by subtracting the mean of the feature and dividing by its standard deviation for each data point.\n",
    "\n",
    "In this scenario:\n",
    "\n",
    "- ‘Age’ will be transformed to have a mean of 0 and a standard deviation of 1.\n",
    "- ‘Salary’ will be transformed to have a mean of 0 and a standard deviation of 1.\n",
    "\n",
    "The process of standardization does not change the unit of measurement; it scales the features to be centered around 0 with a standard deviation of 1, making it easier to compare and analyze them."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
